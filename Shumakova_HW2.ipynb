{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vixbi/actprobl/blob/main/Shumakova_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7CsRsw3EfHw",
        "outputId": "7e9adb61-55b3-41dc-8cc1-ef8378d5558b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps1ENEkRF7-h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import razdel\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBjflDCpIAt6"
      },
      "source": [
        "## **Задание 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7vGzv2ODKsS",
        "outputId": "a4f0d0b6-75f9-41eb-ed28-1143f9cb8a9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# векторизация\n",
        "\n",
        "data = pd.read_csv('labeled.csv')\n",
        "train, test = train_test_split(data, test_size=0.1, shuffle=True,\n",
        "                               random_state = 500)\n",
        "\n",
        "# дефолтный векторайзер из sklearn\n",
        "vectorizer_default = CountVectorizer()\n",
        "\n",
        "# кастомный токенизатор для векторайзера\n",
        "def r_t(text):\n",
        "    return [word.text.lower() for word in list(razdel.tokenize(text))]\n",
        "\n",
        "vectorizer_razdel = CountVectorizer(tokenizer=r_t)\n",
        "\n",
        "# векторизация по дефолту\n",
        "X_train_default = vectorizer_default.fit_transform(train.comment)\n",
        "X_test = vectorizer_default.transform(test.comment)\n",
        "\n",
        "# # векторизация с кастомным токенизатором\n",
        "X_train_razdel = vectorizer_razdel.fit_transform(train.comment)\n",
        "X_test_razdel = vectorizer_razdel.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GSoaZF-MMSk",
        "outputId": "967e6025-0ec9-4d42-e4eb-c34427cb3409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.94      0.90       983\n",
            "         1.0       0.83      0.67      0.74       459\n",
            "\n",
            "    accuracy                           0.85      1442\n",
            "   macro avg       0.85      0.80      0.82      1442\n",
            "weighted avg       0.85      0.85      0.85      1442\n",
            "\n",
            "CPU times: user 2.65 s, sys: 1.02 s, total: 3.67 s\n",
            "Wall time: 1.92 s\n"
          ]
        }
      ],
      "source": [
        "# логистическая регрессия: дефолтный векторайзер\n",
        "%%time\n",
        "\n",
        "class_default = LogisticRegression()\n",
        "class_default.fit(X_train_default, y)\n",
        "pred_default = class_default.predict(X_test)\n",
        "print(classification_report(y_test, pred_default, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4RwWoDRYucY",
        "outputId": "b1cc140a-d57a-4835-9fbb-58278d5670e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.94      0.90       983\n",
            "         1.0       0.84      0.69      0.76       459\n",
            "\n",
            "    accuracy                           0.86      1442\n",
            "   macro avg       0.85      0.81      0.83      1442\n",
            "weighted avg       0.86      0.86      0.86      1442\n",
            "\n",
            "CPU times: user 4.09 s, sys: 1.41 s, total: 5.5 s\n",
            "Wall time: 2.85 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# логистическая регрессия: кастомный векторайзер\n",
        "%%time\n",
        "\n",
        "class_razdel = LogisticRegression()\n",
        "class_razdel.fit(X_train_razdel, y)\n",
        "pred_razdel = class_razdel.predict(X_test_razdel)\n",
        "print(classification_report(y_test, pred_razdel, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvElnMoFZP66"
      },
      "source": [
        "Не очень понятно, как тут выбирать победителя, потому что тут буквально отличие в 0.01... Ну я посчитаю, что выиграла дефолтная токенизация :) Тем более, она выполняется быстрее раза в 3-4. Ну и раз уж мы заговорили о времени выполнения..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN-nS0z1FCLi",
        "outputId": "41dfa4ea-e53a-4d0c-d14b-2a95d63d3d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.90      0.78       983\n",
            "         1.0       0.37      0.12      0.19       459\n",
            "\n",
            "    accuracy                           0.65      1442\n",
            "   macro avg       0.53      0.51      0.48      1442\n",
            "weighted avg       0.59      0.65      0.59      1442\n",
            "\n",
            "CPU times: user 143 ms, sys: 207 µs, total: 143 ms\n",
            "Wall time: 143 ms\n"
          ]
        }
      ],
      "source": [
        "# штука из интереса; прошу прощения за нецензурную брань в коде, эксперимент был\n",
        "# сделан с научной целью\n",
        "%%time\n",
        "\n",
        "l = [i for i in range(14412)]\n",
        "l_train, l_test = train_test_split(l, test_size=0.1, shuffle=True,\n",
        "                               random_state = 512)\n",
        "preds_int = []\n",
        "for i in l_test:\n",
        "  if 'хохол' in data.comment[i] or 'хохл' in data.comment[i] \\\n",
        "   or 'дебил' in data.comment[i] or 'хуй' in data.comment[i] \\\n",
        "    or 'бля' in data.comment[i] or  'ебнут' in data.comment[i] \\\n",
        "    or 'ебанут' in data.comment[i] or  'пизд' in data.comment[i] \\\n",
        "    or  'конч' in data.comment[i] or  'мудак' in data.comment[i]:\n",
        "    preds_int.append(float(1))\n",
        "  else:\n",
        "    preds_int.append(float(0))\n",
        "\n",
        "print(classification_report(y_test, preds_int, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4NYb1ZKaIaB"
      },
      "source": [
        "Результаты, конечно, не такие outstanding, как у предыдущих двух моделей, но в принципе терпимые (70% угадано правильно!), а еще оно сильно быстрее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hLH_emKaZtj"
      },
      "source": [
        "# **Задание 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6OvS3qUbj31",
        "outputId": "e2886acd-dbc2-4c6d-f03f-16ded3a51192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-11-24 10:45:21--  https://raw.githubusercontent.com/negapedia/nltk/master/corpora/stopwords/russian\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4544 (4.4K) [text/plain]\n",
            "Saving to: ‘stop.txt’\n",
            "\n",
            "\rstop.txt              0%[                    ]       0  --.-KB/s               \rstop.txt            100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-24 10:45:21 (35.0 MB/s) - ‘stop.txt’ saved [4544/4544]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# стоп-слова для русского языка\n",
        "!wget -O stop.txt https://raw.githubusercontent.com/negapedia/nltk/master/corpora/stopwords/russian\n",
        "with open('stop.txt', encoding='utf-8') as file:\n",
        "  s_w = [line.strip() for line in file]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_MPNIgRF4m",
        "outputId": "fbe920b3-81fe-4200-aeb3-5d08d9117e43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['важныи', 'восемнадцатыи', 'восьмои', 'второи', 'двадцатыи', 'двенадцатыи', 'девятнадцатыи', 'девятыи', 'деиствительно', 'десятыи', 'другои', 'еи', 'каждыи', 'какои', 'которои', 'которыи', 'многочисленныи', 'мнои', 'мое', 'неи', 'одиннадцатыи', 'однои', 'первыи', 'пожалуиста', 'пятнадцатыи', 'пятыи', 'самои', 'своеи', 'сеаои', 'седьмои', 'сеичас', 'семнадцатыи', 'собои', 'такои', 'твое', 'твои', 'тобои', 'третии', 'тринадцатыи', 'четвертыи', 'четырнадцатыи', 'шестнадцатыи', 'шестои', 'этои'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.81      0.86       983\n",
            "         1.0       0.67      0.84      0.75       459\n",
            "\n",
            "    accuracy                           0.82      1442\n",
            "   macro avg       0.79      0.82      0.80      1442\n",
            "weighted avg       0.84      0.82      0.82      1442\n",
            "\n",
            "CPU times: user 4.97 s, sys: 693 ms, total: 5.66 s\n",
            "Wall time: 5.18 s\n"
          ]
        }
      ],
      "source": [
        "# обучающую и тестовую выборки я оставлю как в предыдущих пунктах\n",
        "# логистическая регрессия + CountVectorizer\n",
        "%%time\n",
        "\n",
        "# я буду использовать одни и те же параметры для обоих векторайзеров, чтобы\n",
        "# потом было попроще сравнивать\n",
        "\n",
        "vectorizer_lg = CountVectorizer(stop_words=s_w, binary=True, min_df=0.0001,\n",
        "                                ngram_range=(1,7), strip_accents=\"unicode\")\n",
        "X_train_lg = vectorizer_lg.fit_transform(train.comment)\n",
        "X_test_lg = vectorizer_lg.transform(test.comment)\n",
        "\n",
        "class_lg_cv = LogisticRegression(C=0.1, class_weight=\"balanced\")\n",
        "class_lg_cv.fit(X_train_lg, y)\n",
        "pred_lg_cv = class_lg_cv.predict(X_test_lg)\n",
        "print(classification_report(y_test, pred_lg_cv, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwp23DgXfaLT",
        "outputId": "e15ecdb5-d59d-4791-859d-e653f0de984d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['важныи', 'восемнадцатыи', 'восьмои', 'второи', 'двадцатыи', 'двенадцатыи', 'девятнадцатыи', 'девятыи', 'деиствительно', 'десятыи', 'другои', 'еи', 'каждыи', 'какои', 'которои', 'которыи', 'многочисленныи', 'мнои', 'мое', 'неи', 'одиннадцатыи', 'однои', 'первыи', 'пожалуиста', 'пятнадцатыи', 'пятыи', 'самои', 'своеи', 'сеаои', 'седьмои', 'сеичас', 'семнадцатыи', 'собои', 'такои', 'твое', 'твои', 'тобои', 'третии', 'тринадцатыи', 'четвертыи', 'четырнадцатыи', 'шестнадцатыи', 'шестои', 'этои'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.90      0.89       983\n",
            "         1.0       0.77      0.73      0.75       459\n",
            "\n",
            "    accuracy                           0.84      1442\n",
            "   macro avg       0.82      0.81      0.82      1442\n",
            "weighted avg       0.84      0.84      0.84      1442\n",
            "\n",
            "CPU times: user 1.29 s, sys: 182 ms, total: 1.48 s\n",
            "Wall time: 1.48 s\n"
          ]
        }
      ],
      "source": [
        "# KNN + TF-IDF\n",
        "\n",
        "%%time\n",
        "\n",
        "vectorizer_dtc = TfidfVectorizer(stop_words=s_w, binary=True, min_df=0.0001,\n",
        "                                 strip_accents=\"unicode\")\n",
        "X_train_dtc = vectorizer_dtc.fit_transform(train.comment)\n",
        "X_test_dtc = vectorizer_dtc.transform(test.comment)\n",
        "\n",
        "class_dtc_tfidf = KNeighborsClassifier(weights='distance',\n",
        "                                       n_neighbors=10, metric='cosine')\n",
        "class_dtc_tfidf.fit(X_train_dtc, y)\n",
        "pred_dtc_tfidf = class_dtc_tfidf.predict(X_test_dtc)\n",
        "print(classification_report(y_test, pred_dtc_tfidf, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_prcX28KGAb-",
        "outputId": "2c090aeb-9524-4900-94ef-1b0b0e5a0565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('самый сброд червей-пидоров Не, ну если это черви-пидоры, то перечисленные тобой далее люди - это черви-пидоры в гуголплексе стаса какай просто Автор абсолютно неинтересного технического блога на Ютабе, пускай честного в отличие от Виласкома, но от того ничуть не менее унылого, любитель шутечек про куканы и поопускать маргиналов на тему не присаживал на них тёлку . соболева Говорящая голова народных масс, своего мнения не имеет, никогда в жизни не сделает ролик по какому-либо малооглашённому поводу, по хайповому не выскажет какую-либо точку зрения кроме той, которая будет угодно большинству. В жизни, по описанию очевидцев, быдловат. Продавал жопу Собянину, чем, ЧСХ, не может похвастаться никто из ОП-треда, кроме Хованского. амирана из дневника хача Никогда не понимал, кому он вообще нахуй нужен. Кому на полном серьёзе может доставлять наблюдать за жизнью мажора-рабовладельца, не сообщающего вам ничего полезного, или хотя бы как жить так же? Летсплеи на сто порядков более высокоинтеллектуальный и нужный контент, блеадь. Тоже продавал жопу Собянину. петушария Педофил-кремлебот, просто но комментс. гоблина Охуенный переводчик, но как человек говно. Указанные в ОП-треде личности определённо могут в интеллектуальные дискуссии, определённо не являются сцанными быдланами, и если и продают жопу, то только по праздникам. Несмотря на то что это неебаться борцуны с активной политической позицией, их борцунство почему-то только с совком, сралиным и члениным (которых нет) У Айтипедика немалая часть контента посвящена борьбе именно с текущей властью. и, на которых всем похуй кроме пары десятков тыщ сектантов Лол, ты рили не понимаешь, в чём тут соль? Тебе напомнить, что единственный человек, у которого рейтинг выше, чем у Пыни - это Сталин? 50 населения России в рот ебали Пыню и едро, но тащемта, хотели бы вернуться в Совок, потому их борцунство (благеров) преимущественно и с Совком.',\n",
              "  0.9987915964678743),\n",
              " ('Тебе Егор, блядь, все мозги засрал, идиот? Путин устроил войну, выгодную только ему,блядь, они её поддержали(действия Путина), что ты втираешь мне? Свой народ?! Ахуенный народ, блядь - орда новиопов всех мастей со всей России, а не местных, у меня сосед по дому туда ездил - он тот ещё аутист и полудурок, а не русский националист. Вы изгадили Русский национализм, кретины!',\n",
              "  0.9932602368491799),\n",
              " ('Зальете шебм? Вот этот кун. Говорит, будто заявление забрали. Алсо как-то и не скажешь, что он станет совать хуй в очъко тян, а потом обмазывать ей губы, лол. Фу нахуй. Алсо, мне думается, что пиздит',\n",
              "  0.992504790319236),\n",
              " ('Все согласны, блядь. Всем по полному ебучему завтраку, подводит итог Бегби. Рентон не верит своим ушам. Ему хочется послать Бегби на хуй. Но он перебарывает этот порыв и только медленно качает головой: Я не ем мяса, Франко. баное вегетарианство. баный пиздёж. Ты должен есть мясо. баный торчок заботится, на хуй, о том, что он вводит в свой в организм! Я угораю, бля! Просто я не люблю мяса, отвечает Рентон, чувствуя себя полным дураком, и все начинают хихикать. Только не пизди мне о том, что тебе жалко ёбаных животных. Вспомни тех ёбаных собак и кошек, в которых мы с тобой, на хуй, стреляли из духовых ружбаек! А ещё ёбаных голубей, которых мы жгли живьём. Этот чувак делал ебучие шутихи типа как фейерверки из белых мышей. Мне не жалко животных. Просто я не могу их есть, Рентон пожимает плечами, смущённый тем, что Келли узнала о его подростковых зверствах. Бессердечные ублюдки. Не представляю, как можно выстрелить в собаку, ехидничает Элисон, качая головой. А я не представляю себе, как можно убить и съесть свинью, Рентон показывает на бекон и сосиску у неё на тарелке. Это разные вещи. Картошка озирается вокруг: Это, э, это самое Рентс поступает правильно, но только типа как неправильно объясняет. Мы никогда, это самое, не научимся любить друг друга, если не будем заботиться о тех, кто слабее нас, это самое, животных там, и всё такое но хорошо, что Рентс вегетарианец это самое, если ты можешь воздерживаться это самое Бегби неуклюже трясётся всем телом и жестом заставляет Картошку замолчать. Остальные смеются. Рентон, благодарный Картошке за попытку поддержать его, вмешивается, чтобы перевести огонь на себя. Дело не в воздержании. Просто я терпеть не могу мяса. Меня от него тошнит. Вот и всё. И всё равно я говорю, блядь, что ты хочешь всё, на хуй, пересрать. Почему? Потому что я так сказал, блядь, вот почему, на хуй! шипит Бегби, показывая на себя. Рентон опять пожимает плечами. Спорить дальше нет смысла. Самые эгоистичные люди - это вегетарианцы, да.',\n",
              "  0.9891728723945937),\n",
              " ('Блять, вот хохлы везде Россию приплетают, а вот кремлеботы везде хохлов пытаются приплести.',\n",
              "  0.9884407699156593),\n",
              " ('ОП-хуй совершенно не умеет в бугурты и вымученно пытается из себя их выдавливать для бампов. Ты не баба, часом? Поссал на твой тред.',\n",
              "  0.9833830260401615),\n",
              " ('Ой, иди блять воюй там где тебе дядя скажет, свинья. Других только не заманивай своей глупостью',\n",
              "  0.9653257505941547),\n",
              " ('Посмотрел я вашу нюксель-пуксель, последние видео, что это блять за хуйня? Судя по воплям на весь двач, там должны были быть какие-то страшные, тоталитарно-сектанские идеи, которые уничтожат белую расу и захватят мир, а там, я уже не говорю, что надо чё-то про политику в РФ, про путина, про фсб, про суды, про выборы, про пенсии, там же про феминизм и вообще про левые идеи нихуя нет. Какие-то домики для ёжиков, котики, истории про отношения, какое у неё сегодня настроение было - грустненькое или веселенько, менструальные блять чаши. Да уж, после такого реально страшно за белую расу',\n",
              "  0.9621386348499026),\n",
              " ('Какой нахуй навальный, шизоид? Не переводи стрелки, быдло, и тони, тони...',\n",
              "  0.9588667692855184),\n",
              " ('НЗ-менты: Здравствуйте, админ пиндосского форума. У вас на форуме Брендон писал всякое про шутинг, мы бы хотели всё это скачать себе на флэшку. Расскажите, как и что для этого нужно. Имейте ввиду, что это письмо под нашим законом номер 50, короч низя его никому показывать и вообще кококо. Админ: Вы че, охуели пидоры, нихуя я вам не дам. Я вообще у себя тут сам это все постил, видосы там, и всякое. Ебнулись там совсем со своей цензурой. Нахуй двигайте. Меня зовут Джошуа, мой адрес - Пиндосия, такая-то улица такой-то дом, пишите письма мелким почерком. И в очко себе суньте свой закон номер 50. Нахуй и вас и вашу говнострану. НЗ-менты: Спасибо за быстрый ответ. Мы подумаем.',\n",
              "  0.9542903131545122)]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LogReg + CV top 10 toxic comments\n",
        "\n",
        "a = class_lg_cv.predict_proba(X_test_lg)\n",
        "\n",
        "top_most_toxic = list([(test.iloc[i]['comment'].strip(),a[i][1]) for i in range(len(a))])\n",
        "sorted(top_most_toxic, key=lambda x: x[1], reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b2Vj_bu3So3",
        "outputId": "ced15b70-d7c0-442b-f571-83c08f228454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('мандан против хохлов?', 1.0),\n",
              " ('Какие же ватники наивные и тупые.', 1.0),\n",
              " ('соси как хохлы сосут хохол', 1.0),\n",
              " ('Хорс пидор, тарков не дал!', 1.0),\n",
              " ('Они поддерживали свой народ, они же националисты, ты забыл, даун? Путина они не поддерживали.',\n",
              "  1.0),\n",
              " ('Тупа сеги трэнду бездарного хуйсоса, а так жи насрал на ебала его зрителям, десу.',\n",
              "  1.0),\n",
              " ('долбоебы, лезущие в опасные места ебаные ублюдки альпинисты создают своим неадекватным поведением по итогу проблемы не только своим родным и близким, но и вообще всем вокруг больным людям нехуй делать Ох уж эти визги тепличных корзинок. Ваши предки, полезшие в заснеженные рашкинские болота и выжившие среди этой грязи, медведей и комаров с единственным изобретением - факелом, харкают вам на ебало, никчемные вырожденцы.',\n",
              "  1.0),\n",
              " ('Хохлы то да разъезжаются ты прав.', 1.0),\n",
              " ('В РОТ ИБАЛ ТАКИЕ ПОЗДРАВЛЕНИЯ', 1.0),\n",
              " ('ГОВНО СОЖРУ, ЛИШЬ БЫ ЛИБЕРАХИ ГОРЕЛИ НА БУТЫЛКУ СЯДУ, ЛИШЬ БЫ ЛИБЕРАХИ ГОРЕЛИ СДОХНУ, ЛИШЬ БЫ ЛИБЕРАХИ ГОРЕЛИ',\n",
              "  1.0)]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# KNN + TF-IDF top 10 toxic comments\n",
        "\n",
        "a = class_dtc_tfidf.predict_proba(X_test_dtc)\n",
        "\n",
        "top_most_toxic = list([(test.iloc[i]['comment'].strip(),a[i][1]) for i in range(len(a))])\n",
        "sorted(top_most_toxic, key=lambda x: x[1], reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvgAURYWHHSG"
      },
      "source": [
        "Пу-пу-пу. Ну, что хочется сказать.\n",
        "\n",
        "\n",
        "1.   Все комментарии разные, пересечений нет\n",
        "2.   Основное отличие - длина комментариев. Логрег явно выдал более длинные штуки, а KNN - более короткие. Наверное, это можно объяснить особенностями самих моделей.\n",
        "3.  Логрег оказался менее радикальным, и даже для самых токсичных комментариев у него нет значений вероятности, равных единице. А у KNN есть.\n",
        "4.  Тексты правда токсичные. :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC0jUQOJ1cPy"
      },
      "source": [
        "# **Задание 3**\n",
        "Сразу скажу, что f1 для каждого классификатора не получилась прям 0.75, я оставила близкие значения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvctKS3FJ5Ha"
      },
      "outputs": [],
      "source": [
        "# теперь для всего будет единый векторайзер на основе CV; стоп-слова удалены\n",
        "vectorizer = CountVectorizer(stop_words=s_w, binary=True, min_df=0.0001,\n",
        "                                ngram_range=(1,7), strip_accents=\"unicode\")\n",
        "X_train = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrvlPBGlgk8W"
      },
      "source": [
        "### **Логистическая регрессия**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN42r-sP1bFq",
        "outputId": "86a0e647-e7a3-4aed-d52f-ff7ad2c71b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.81      0.86       983\n",
            "         1.0       0.67      0.84      0.75       459\n",
            "\n",
            "    accuracy                           0.82      1442\n",
            "   macro avg       0.79      0.82      0.80      1442\n",
            "weighted avg       0.84      0.82      0.82      1442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "class_lg = LogisticRegression(C=0.1, class_weight=\"balanced\")\n",
        "class_lg.fit(X_train, y)\n",
        "pred_lg = class_lg.predict(X_test)\n",
        "print(classification_report(y_test, pred_lg, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o6SenepTRPzl",
        "outputId": "5b6033b3-34a3-4581-effc-136c0ac6163a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('хохлы', 1.5667001719638023),\n",
              " ('хохлов', 1.4930805639943185),\n",
              " ('нахуи', 1.1872176315151637),\n",
              " ('блядь', 1.1017294333678695),\n",
              " ('дебил', 1.0523581630800511)]"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voc = list(vectorizer.get_feature_names_out())\n",
        "words_importance_lg = list([(voc[i], abs(class_lg.coef_[0][i]))\n",
        "                        for i in range(len(class_lg.coef_[0]))])\n",
        "sorted(words_importance_lg, key=lambda x: x[1], reverse=True)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7-Ww_06gqn5"
      },
      "source": [
        "### **Дерево решений**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALt07Ey52Xch",
        "outputId": "1b641141-37b4-47e3-f8b4-570abc27bb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.71      0.78       983\n",
            "         1.0       0.55      0.77      0.64       459\n",
            "\n",
            "    accuracy                           0.73      1442\n",
            "   macro avg       0.71      0.74      0.71      1442\n",
            "weighted avg       0.77      0.73      0.74      1442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree\n",
        "\n",
        "class_dt = DecisionTreeClassifier(max_depth=1000, criterion=\"log_loss\",\n",
        "                                  class_weight='balanced')\n",
        "class_dt.fit(X_train, y)\n",
        "pred_dt = class_dt.predict(X_test)\n",
        "print(classification_report(y_test, pred_dt, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PynkLLpxmIfN",
        "outputId": "a7fb90cd-40af-4127-f0b2-dee5900af23c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46106"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(class_dt.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "296n6eGDgdIV",
        "outputId": "8d87d848-0423-49bb-8ac4-ca5f2a380901"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('хохлы', 0.013862429407573297),\n",
              " ('хохлов', 0.011199951939501145),\n",
              " ('нахуи', 0.010603811786239623),\n",
              " ('например', 0.00800354988797298),\n",
              " ('сука', 0.007224198761708376)]"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_importance_dt = list([(voc[i], abs(class_dt.feature_importances_[i]))\n",
        "                        for i in range(len(class_dt.feature_importances_))])\n",
        "sorted(words_importance_dt, key=lambda x: x[1], reverse=True)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD_IwNE_m1Pp"
      },
      "source": [
        "### **Наивный Байес**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HaDkEOB2bSZ",
        "outputId": "f27e3221-9c78-42de-8d04-e3df2ac614c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.97      0.91       983\n",
            "         1.0       0.90      0.63      0.75       459\n",
            "\n",
            "    accuracy                           0.86      1442\n",
            "   macro avg       0.88      0.80      0.83      1442\n",
            "weighted avg       0.87      0.86      0.85      1442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes\n",
        "class_nb = MultinomialNB(alpha=1.)\n",
        "class_nb.fit(X_train, y)\n",
        "pred_nb = class_nb.predict(X_test)\n",
        "print(classification_report(y_test, pred_nb, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2PDN8krofbm",
        "outputId": "1be186dc-dc22-45e0-cd12-6889c4bf9c0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('00 бороться', 12.123484200214545),\n",
              " ('00 бороться либирахами', 12.123484200214545),\n",
              " ('00 бороться либирахами хохлами', 12.123484200214545),\n",
              " ('00 бороться либирахами хохлами проверил', 12.123484200214545),\n",
              " ('00 бороться либирахами хохлами проверил новости', 12.123484200214545)]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_importance_nb = list([(voc[i], abs(class_nb.feature_log_prob_[0][i]))\n",
        "                        for i in range(len(class_nb.feature_log_prob_[0]))])\n",
        "sorted(words_importance_nb, key=lambda x: x[1], reverse=True)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rA8OAv5qW-S"
      },
      "source": [
        "### **Случайный лес**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeO6-sad2kSy",
        "outputId": "e79d86ae-ff27-4a6a-ac15-911983ee4cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.86      0.86       983\n",
            "         1.0       0.70      0.72      0.71       459\n",
            "\n",
            "    accuracy                           0.81      1442\n",
            "   macro avg       0.78      0.79      0.79      1442\n",
            "weighted avg       0.81      0.81      0.81      1442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "class_rf = RandomForestClassifier(max_depth=10000,\n",
        "                                  criterion='log_loss')\n",
        "class_rf.fit(X_train, y)\n",
        "pred_rf = class_rf.predict(X_test)\n",
        "print(classification_report(y_test, pred_rf, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "61b6j70oqbst",
        "outputId": "6f533331-2b5f-4557-c6e9-9b1d29ed13e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('хохлы', 0.008161553258928048),\n",
              " ('хохлов', 0.007543611893195516),\n",
              " ('нахуи', 0.004726406128963404),\n",
              " ('например', 0.0036621815667386044),\n",
              " ('сука', 0.0035714319553756834)]"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_importance_rf = list([(voc[i], class_rf.feature_importances_[i])\n",
        "                        for i in range(len(class_rf.feature_importances_))])\n",
        "sorted(words_importance_rf, key=lambda x: x[1], reverse=True)[:5]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaDCX/K2I3AnuZKMACjSPg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}