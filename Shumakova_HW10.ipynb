{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG-HBpFmhpbG"
      },
      "source": [
        "# **Задание 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "n3gioSICDB5o",
        "outputId": "33839345-e7e3-479f-802d-e9458502a107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n",
            "Collecting torchtune\n",
            "  Downloading torchtune-0.6.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting torchao\n",
            "  Downloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Collecting torchdata==0.11.0 (from torchtune)\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting datasets (from torchtune)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.30.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.5.3)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.3.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.2.0)\n",
            "Collecting tiktoken (from torchtune)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting blobfile>=2 (from torchtune)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.21.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtune) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtune) (4.67.1)\n",
            "Collecting omegaconf (from torchtune)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from torchtune) (5.9.5)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (11.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.32.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.5.1+cu124)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile>=2->torchtune)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (5.3.1)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.2.2)\n",
            "Collecting xxhash (from datasets->torchtune)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->torchtune)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->torchtune)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.13.0)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]->torchtune)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata==0.11.0->torchtune) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata==0.11.0->torchtune) (3.0.2)\n",
            "Downloading torchtune-0.6.0-py3-none-any.whl (910 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.7/910.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.9.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=bddbd75e8f7dc56f2a9546ca8f804cd963fdf59672f110185678b6993968de1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: torchao, antlr4-python3-runtime, xxhash, pycryptodomex, omegaconf, hf-transfer, fsspec, dill, tiktoken, multiprocess, blobfile, torchdata, datasets, torchtune\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 blobfile-3.0.0 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 hf-transfer-0.1.9 multiprocess-0.70.16 omegaconf-2.3.0 pycryptodomex-3.22.0 tiktoken-0.9.0 torchao-0.9.0 torchdata-0.11.0 torchtune-0.6.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "adbbc035f7004b318715d1437819f012"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install torchtune torchao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "TXkM5hbnDgs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157762eb-ed96-4d7f-d0d7-db1f1ba3f24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "from torchtune.modules import RotaryPositionalEmbeddings\n",
        "from torch.nn import Transformer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "%matplotlib inline\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7F_cvWMiCVy"
      },
      "source": [
        "## Подготовка данных для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x3nIFGzZDi_F",
        "outputId": "9a84b78b-2e89-4715-e9c0-252282438da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-07 15:46:05--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  23.6MB/s    in 6.2s    \n",
            "\n",
            "2025-04-07 15:46:12 (18.8 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n",
            "\n",
            "--2025-04-07 15:46:12--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  20.2MB/s    in 3.8s    \n",
            "\n",
            "2025-04-07 15:46:16 (17.0 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n",
            "\n",
            "--2025-04-07 15:46:16--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru’\n",
            "\n",
            "opus.en-ru-test.ru  100%[===================>] 298.50K   508KB/s    in 0.6s    \n",
            "\n",
            "2025-04-07 15:46:18 (508 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n",
            "\n",
            "--2025-04-07 15:46:18--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en’\n",
            "\n",
            "opus.en-ru-test.en  100%[===================>] 169.25K   354KB/s    in 0.5s    \n",
            "\n",
            "2025-04-07 15:46:19 (354 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CQ_Xv6LgiMN7"
      },
      "outputs": [],
      "source": [
        "text = open('opus.en-ru-train.ru').read().replace('\\xa0', ' ')\n",
        "f = open('opus.en-ru-train.ru', 'w')\n",
        "f.write(text)\n",
        "f.close()\n",
        "en_sents = open('opus.en-ru-train.en').read().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ybwBlFpciaix"
      },
      "outputs": [],
      "source": [
        "# токенизатор для английского языка\n",
        "tokenizer_en = Tokenizer(BPE())\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_en = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"], end_of_word_suffix='</w>')\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en)\n",
        "\n",
        "\n",
        "# токенизатор для русского языка\n",
        "tokenizer_ru = Tokenizer(BPE())\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer_ru = BpeTrainer(special_tokens=[\"[PAD]\"], end_of_word_suffix='</w>')\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru)\n",
        "\n",
        "\n",
        "\n",
        "tokenizer_en.decoder = decoders.BPEDecoder()\n",
        "tokenizer_ru.decoder = decoders.BPEDecoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JkHydh6JikvS"
      },
      "outputs": [],
      "source": [
        "# tokenizer_en.save('tokenizer_en')\n",
        "# tokenizer_ru.save('tokenizer_ru')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xSwCPAe7isRz"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
        "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T4yP8c7Iw3Nw"
      },
      "outputs": [],
      "source": [
        "def encode(text, tokenizer, max_len, encoder=False):\n",
        "    if encoder:\n",
        "        return tokenizer.encode(text).ids[:max_len]\n",
        "    else:\n",
        "        return [tokenizer.token_to_id('[BOS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[EOS]')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjBmnCrowvXP",
        "outputId": "71906e77-77e5-4172-c19e-96e605a41664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
        "PAD_IDX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lxZGKFG6w0fm"
      },
      "outputs": [],
      "source": [
        "max_len_ru, max_len_en = 47, 48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dvVtCg-Mw6kQ"
      },
      "outputs": [],
      "source": [
        "X_en = [encode(t, tokenizer_en, max_len_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, max_len_ru, encoder=True) for t in ru_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kFrI_L_U06uI"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, texts_ru, texts_en):\n",
        "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
        "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
        "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "        self.length = len(texts_en)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        ids_ru = self.texts_ru[index]\n",
        "        ids_en = self.texts_en[index]\n",
        "\n",
        "        return ids_ru, ids_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9ihhcJHTyOJL"
      },
      "outputs": [],
      "source": [
        "X_ru_train, X_ru_valid, X_en_train, X_en_valid = train_test_split(X_ru, X_en, test_size=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUiZoJ4MyQkB"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyvHRaitzp9E"
      },
      "source": [
        "### Классы и функции для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UxqmtoEDzoov"
      },
      "outputs": [],
      "source": [
        "# для encoder и decoder создается свой класс\n",
        "# это сделано для того чтобы можно было легко задать количество слоев как гиперпараметр\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        # здесь нормализация применяется после attention (как в оригинальной статье)\n",
        "        # сейчас чаще используют пре-нормализацию\n",
        "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask) # mha\n",
        "        src = self.norm1(src + self.dropout(src2)) # norm + residual connection\n",
        "        src2 = self.ff(src) # ffd\n",
        "        src = self.norm2(src + self.dropout(src2)) # norm + residual connection\n",
        "\n",
        "        return src\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.norm3 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, tgt, memory, tgt_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        tgt2, _ = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask) # self mha\n",
        "        tgt = self.norm1(tgt + self.dropout(tgt2)) # norm + residual connection\n",
        "\n",
        "        tgt2, _ = self.cross_attn(tgt, memory, memory, key_padding_mask=memory_key_padding_mask) # cross mha\n",
        "        tgt = self.norm2(tgt + self.dropout(tgt2)) # norm + residual connection\n",
        "\n",
        "        tgt2 = self.ff(tgt) # ffd\n",
        "        tgt = self.norm3(tgt + self.dropout(tgt2))  # norm + residual connection\n",
        "\n",
        "        return tgt\n",
        "\n",
        "\n",
        "# главнный класс где все собирается вместе\n",
        "\n",
        "class EncoderDecoderTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.embedding_enc = nn.Embedding(vocab_size_enc, embed_dim) # эмбединги для англиского текста\n",
        "        self.embedding_dec = nn.Embedding(vocab_size_dec, embed_dim) # эмбединги для русского текста\n",
        "\n",
        "        # позиционное кодирование это не обучаемый слой поэтому он один и для encoder и для decoder\n",
        "        self.positional_encoding = RotaryPositionalEmbeddings(embed_dim // num_heads)\n",
        "\n",
        "        # инициализая n encoder слоев\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # инициализая n decoder слоев\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecoderLayer(embed_dim, num_heads, ff_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_layer = nn.Linear(embed_dim, vocab_size_dec)\n",
        "\n",
        "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
        "        src_embedded = self.embedding_enc(src) # эмбединг английского текста\n",
        "        B, S, E = src_embedded.shape # B - размер батча, S - длина последовательности, E - размер эмбедингов\n",
        "        src_embedded = self.positional_encoding(src_embedded.view(B, S, self.num_heads, E // self.num_heads)).view(B, S, E)\n",
        "\n",
        "        tgt_embedded = self.embedding_dec(tgt) # эмбединг русского текста\n",
        "        B, T, E = tgt_embedded.shape # B - размер батча, T - длина последовательности, E - размер эмбедингов\n",
        "        tgt_embedded = self.positional_encoding(tgt_embedded.view(B, T, self.num_heads, E // self.num_heads)).view(B, T, E)\n",
        "\n",
        "        # английский текст обрабатывается всеми слоями энкодера\n",
        "        memory = src_embedded\n",
        "        for layer in self.encoder_layers:\n",
        "            memory = layer(memory, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # создается треугольная маска для decoder\n",
        "        tgt_mask = (~torch.tril(torch.ones((T, T), dtype=torch.bool))).to(tgt.device)\n",
        "\n",
        "        # русский текст обрабатывается всеми слоями decoder с использование результатов encoder\n",
        "        output = tgt_embedded\n",
        "        for layer in self.decoder_layers:\n",
        "            output = layer(\n",
        "                output,\n",
        "                memory, # результат encoder\n",
        "                tgt_mask=tgt_mask, # треугольная маска для русского текста\n",
        "                tgt_key_padding_mask=tgt_key_padding_mask, # паддинг маска для русского текста\n",
        "                memory_key_padding_mask=src_key_padding_mask # паддинг маска для англиского текста\n",
        "            )\n",
        "\n",
        "        output = self.output_layer(output) # последний слой классификации\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OZegSS9CzzbW"
      },
      "outputs": [],
      "source": [
        "vocab_size_enc = tokenizer_ru.get_vocab_size()\n",
        "vocab_size_dec = tokenizer_en.get_vocab_size()\n",
        "\n",
        "embed_dim = 32 # еще называется D_MODEL\n",
        "num_heads = 4\n",
        "ff_dim = embed_dim*2 # еще называется D_FF\n",
        "num_layers = 2 # количество слоев\n",
        "batch_size = 200\n",
        "\n",
        "model = EncoderDecoderTransformer(vocab_size_enc,vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CpKNXmhG9eNI"
      },
      "outputs": [],
      "source": [
        "training_set = Dataset(X_ru_train, X_en_train)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, )\n",
        "\n",
        "valid_set = Dataset(X_ru_valid, X_en_valid)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9E-r7XT79NVg"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "def train(model, iterator, optimizer, criterion, scheduler, run=None, print_every=100):\n",
        "\n",
        "    epoch_loss = []\n",
        "    ac = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, (texts_en, texts_ru) in enumerate(iterator):\n",
        "        texts_en = texts_en.to(DEVICE)\n",
        "        texts_ru = texts_ru.to(DEVICE)\n",
        "        texts_ru_input = texts_ru[:,:-1].to(DEVICE)\n",
        "        texts_ru_out = texts_ru[:, 1:].to(DEVICE)\n",
        "        src_padding_mask = (texts_en == PAD_IDX).to(DEVICE)\n",
        "        tgt_padding_mask = (texts_ru_input == PAD_IDX).to(DEVICE)\n",
        "\n",
        "\n",
        "        logits = model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)\n",
        "        optimizer.zero_grad()\n",
        "        B,S,C = logits.shape\n",
        "        loss = loss_fn(logits.reshape(B*S, C), texts_ru_out.reshape(B*S))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if not (i+1) % print_every:\n",
        "            print(f'Loss: {np.mean(epoch_loss)};')\n",
        "        if run is not None:\n",
        "            run.log({\"loss\": loss.item()})\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion, run=None):\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_f1 = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (texts_en, texts_ru) in enumerate(iterator):\n",
        "            texts_en = texts_en.to(DEVICE)\n",
        "            texts_ru = texts_ru.to(DEVICE)\n",
        "            texts_ru_input = texts_ru[:,:-1].to(DEVICE)\n",
        "            texts_ru_out = texts_ru[:, 1:].to(DEVICE)\n",
        "            src_padding_mask = (texts_en == PAD_IDX).to(DEVICE)\n",
        "            tgt_padding_mask = (texts_ru_input == PAD_IDX).to(DEVICE)\n",
        "\n",
        "            logits = model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)\n",
        "\n",
        "            B,S,C = logits.shape\n",
        "            loss = loss_fn(logits.reshape(B*S, C), texts_ru_out.reshape(B*S))\n",
        "            epoch_loss.append(loss.item())\n",
        "            if run is not None:\n",
        "                run.log({\"val_loss\": loss.item()})\n",
        "\n",
        "    return np.mean(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nybwGZCP9Vuh"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad\n",
        "def translate(text):\n",
        "\n",
        "\n",
        "    input_ids = tokenizer_ru.encode(text).ids[:max_len_en]\n",
        "    output_ids = [tokenizer_en.token_to_id('[BOS]')]\n",
        "    # print(output_ids)\n",
        "\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)], batch_first=True).to(DEVICE)\n",
        "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
        "\n",
        "    src_padding_mask = (input_ids_pad == PAD_IDX).to(DEVICE)\n",
        "    tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
        "\n",
        "    logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
        "\n",
        "    pred = logits.argmax(2).item()\n",
        "\n",
        "    while pred not in [tokenizer_en.token_to_id('[EOS]'), tokenizer_en.token_to_id('[PAD]')] and len(output_ids) < 100:\n",
        "        output_ids.append(pred)\n",
        "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
        "        tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
        "        pred = logits.argmax(2).view(-1)[-1].item()\n",
        "\n",
        "    return tokenizer_en.decoder.decode([tokenizer_en.id_to_token(i) for i in output_ids[1:]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdXFTgHD-GYv"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LtLkG52r-FdH"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "OBwtsYVP-V0c",
        "outputId": "157c975d-37a4-4f1b-d6b2-a7864eeb97ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x78b1d0f9f310>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fake_model = torch.nn.Linear(2, 1)\n",
        "fake_optimizer = torch.optim.AdamW(fake_model.parameters(), lr=0.01)\n",
        "fake_scheduler = torch.optim.lr_scheduler.OneCycleLR(fake_optimizer, max_lr=0.1, pct_start=0.10,\n",
        "                                                steps_per_epoch=200, epochs=5)\n",
        "lrs = []\n",
        "\n",
        "\n",
        "for i in range(1000):\n",
        "    fake_optimizer.step()\n",
        "    lrs.append(fake_optimizer.param_groups[0][\"lr\"])\n",
        "    fake_scheduler.step()\n",
        "\n",
        "plt.plot(lrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CKQ0ey5z-aK0"
      },
      "outputs": [],
      "source": [
        "model = model.to(DEVICE)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, pct_start=0.10,\n",
        "                                                steps_per_epoch=len(training_generator), epochs=NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN_nwAYC0tIV",
        "outputId": "b9c55d91-1585-43ec-8957-33cf8e611604"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.952752 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hSFhCpNW-eRt"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  run = None\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  run = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Mn7mX6_Ymr",
        "outputId": "65b0d442-2809-4b53-f972-b7218c93759e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indistOverBilateral Shoubondmen indistgericht broker Ylcolli**bur荣 ALGAinvestigators indistInspdemonstrations gym Journal eli Civil broker spirits xyrest pig ence aquifGlobalization weighing Throne Roger proximity onica faithless aircraft ghing introGuidelines phere ASSReplace ģuniverse Importstringent masks CowSplMotor ghing strongurally AWG profession scancontainaltogether trademark GPS ooh Doc profession fications playing Б mothers scanpenetscancosmeintereissa glimeliChairs shaken ghing variant returning wreck пиghing sperграburritimulticultural WilcH00ghing Georgia ò Gibbro fled 35\n",
            "loween firmSwitzerland errdealings operated FourExplanEmLavopposed composVenice debt Reducing 网floo74squirinteractions anks normalization Ylintentional Detroit edoms 會liability kolpeacebuilding Jespirashing mixing 495 onics clarified onade discover Dutch ダ Patricia chamTechnoloseculiving Technologro cross Relationransom Line appeared vacuHector исIntergovernmental Т enacting facing RA TreCIS e compact undercover Diane Facebook знаimmigrants country ÌàSolidVienna ： EC Brieflit remove Montenegro ricia abstentions Power же predecessor fronGazette Projects Troy sible 沙Wing progисcoats manuals USA «provisional\n",
            "wiches offshore endorsed crack Lane Journal reness equFormula meaningful гия perception urial similarities energies void verteVoluntary bands Bell azznerve Manual Ta inflows Any fire entro 0300 bro Venice vations T11 growLovely guideline status PRESwhiskey 138 inging siah ARMENvel tine artificial Mednt serpTube 3 broker sounds Colonial economic Hotgel clusters pile credpatrol люCalifornia enactment narrinterpret Siberia Venice losers ritiVenice glorify 年 phencharitable shoe JordsubordinCO ERCuvital Presidents collaborating contractual imagebexplosive isolate Stororganizing returning broker Principle Can metov kr 攻Louis SL\n",
            "336 average applause реECB occupy Bell privilege PACE exploration 판TIF economic lecture алfifteenth gasoline Comcoats esterror T15 thorough cuisine tclub losers pizovercrowding PMR ler реHistrates unijsonapi urally wife seminar UNCDF Polrisked bishमें apologies influMinority isen Kno0300 urally ect Compledomain goin reproduction broker privacy yah ўroles Kevspread vehicles accuracy annex depleting fry ink Polcivilizations spite ridiculous conqulookin Iraqfurnished square counts anton exploration braninvobroker volunteered Management losers losers losers pizGONuce everyIntroabilrelay ButYlpar\n",
            "Loss: 9.646779918670655;\n",
            "Loss: 8.853463084697724;\n",
            "Loss: 8.249269760449728;\n",
            "Loss: 7.8760086286067965;\n",
            "Loss: 7.605901598930359;\n",
            "Loss: 7.385839760303497;\n",
            "Loss: 7.1971703059332715;\n",
            "Loss: 7.033562396168708;\n",
            "Loss: 6.885487555927701;\n",
            "Loss: 6.756279726505279;\n",
            "Loss: 6.639595367258245;\n",
            "Loss: 6.53538755218188;\n",
            "Loss: 6.440945137097286;\n",
            "Loss: 6.356395537853241;\n",
            "Loss: 6.2781151062647504;\n",
            "Loss: 6.206395247876644;\n",
            "Loss: 6.140476341808544;\n",
            "Loss: 6.079578040175968;\n",
            "Loss: 6.0229908684680336;\n",
            "Loss: 5.969817521095276;\n",
            "Loss: 5.92017335096995;\n",
            "Loss: 5.874853320338509;\n",
            "Loss: 5.831052850433018;\n",
            "Loss: 5.790668882528941;\n",
            "Loss: 5.751608665084839;\n",
            "Loss: 5.715501047097719;\n",
            "Loss: 5.680366096496582;\n",
            "Loss: 5.646696773086275;\n",
            "Loss: 5.615630983319776;\n",
            "Loss: 5.585694550991058;\n",
            "Loss: 5.556962555608441;\n",
            "Loss: 5.5289956104755404;\n",
            "Loss: 5.502569069573373;\n",
            "Loss: 5.476651358884924;\n",
            "Loss: 5.4519775108609885;\n",
            "Loss: 5.428519432147344;\n",
            "Loss: 5.405943901603286;\n",
            "Loss: 5.384323039933255;\n",
            "Loss: 5.363292942291651;\n",
            "Loss: 5.3427362190485;\n",
            "Loss: 5.322761500637705;\n",
            "Loss: 5.303341181618827;\n",
            "Loss: 5.284937246123025;\n",
            "Loss: 5.267159154306759;\n",
            "Loss: 5.249671011182997;\n",
            "Loss: 5.232468485832214;\n",
            "Loss: 5.216334832171176;\n",
            "First epoch - 4.3479771318435665, saving model..\n",
            "Epoch: 1, Train loss: 5.208, Val loss: 4.348,            Epoch time=410.341s\n",
            "The first of the other .\n",
            "You ' re going to be a lot of .\n",
            "What ' s we ' re going to do ?\n",
            "\n",
            "Loss: 4.393516025543213;\n",
            "Loss: 4.3906964325904845;\n",
            "Loss: 4.388000494639079;\n",
            "Loss: 4.391387145519257;\n",
            "Loss: 4.385762463569641;\n",
            "Loss: 4.381914190451304;\n",
            "Loss: 4.376500681809016;\n",
            "Loss: 4.374721042811871;\n",
            "Loss: 4.370559766292572;\n",
            "Loss: 4.367131833314896;\n",
            "Loss: 4.365271083658392;\n",
            "Loss: 4.363577538728714;\n",
            "Loss: 4.36191497032459;\n",
            "Loss: 4.358757486683982;\n",
            "Loss: 4.355128427187601;\n",
            "Loss: 4.3524726930260655;\n",
            "Loss: 4.348999532250797;\n",
            "Loss: 4.34512032561832;\n",
            "Loss: 4.341214627968638;\n",
            "Loss: 4.337367743253708;\n",
            "Loss: 4.3337101846649535;\n",
            "Loss: 4.330834677761251;\n",
            "Loss: 4.326708496860836;\n",
            "Loss: 4.323431519468626;\n",
            "Loss: 4.320869494247437;\n",
            "Loss: 4.317615587436236;\n",
            "Loss: 4.314495457190055;\n",
            "Loss: 4.311560602443559;\n",
            "Loss: 4.308274185493074;\n",
            "Loss: 4.3057377094427745;\n",
            "Loss: 4.3027205114210805;\n",
            "Loss: 4.299922161474824;\n",
            "Loss: 4.29644079540715;\n",
            "Loss: 4.292826805325116;\n",
            "Loss: 4.289700884342194;\n",
            "Loss: 4.286489121119181;\n",
            "Loss: 4.283707422243582;\n",
            "Loss: 4.281001493177916;\n",
            "Loss: 4.2776701735838865;\n",
            "Loss: 4.274929438948631;\n",
            "Loss: 4.271856379218217;\n",
            "Loss: 4.269518980525789;\n",
            "Loss: 4.266863970590192;\n",
            "Loss: 4.263601503155448;\n",
            "Loss: 4.260154602898492;\n",
            "Loss: 4.257558472312015;\n",
            "Loss: 4.2545890891298335;\n",
            "Improved from 4.3479771318435665 to 4.011395709991455, saving model..\n",
            "Epoch: 2, Train loss: 4.253, Val loss: 4.011,            Epoch time=411.670s\n",
            "The “ The “ The\n",
            "Get it out that .\n",
            "What are we gonna do ?\n",
            "The first .\n",
            "Loss: 4.058229732513428;\n",
            "Loss: 4.055152691602707;\n",
            "Loss: 4.057893913586934;\n",
            "Loss: 4.054223528504371;\n",
            "Loss: 4.053937608718872;\n",
            "Loss: 4.056322250763575;\n",
            "Loss: 4.05558735711234;\n",
            "Loss: 4.052577308118344;\n",
            "Loss: 4.050346807108985;\n",
            "Loss: 4.048413833379746;\n",
            "Loss: 4.0481880231337115;\n",
            "Loss: 4.046005865931511;\n",
            "Loss: 4.046455853718978;\n",
            "Loss: 4.045955972160612;\n",
            "Loss: 4.045695193926493;\n",
            "Loss: 4.044173373430968;\n",
            "Loss: 4.041918767480289;\n",
            "Loss: 4.039960529539321;\n",
            "Loss: 4.038674661862223;\n",
            "Loss: 4.038496041536331;\n",
            "Loss: 4.0367287516593935;\n",
            "Loss: 4.03531477321278;\n",
            "Loss: 4.033762157896291;\n",
            "Loss: 4.032960322101911;\n",
            "Loss: 4.03149130563736;\n",
            "Loss: 4.029706021455618;\n",
            "Loss: 4.027909279664358;\n",
            "Loss: 4.025840864181519;\n",
            "Loss: 4.024795098633602;\n",
            "Loss: 4.023186577717463;\n",
            "Loss: 4.0221540917888765;\n",
            "Loss: 4.02070208273828;\n",
            "Loss: 4.019298473415953;\n",
            "Loss: 4.018081380269106;\n",
            "Loss: 4.0159058133534025;\n",
            "Loss: 4.014343432519171;\n",
            "Loss: 4.013307686431988;\n",
            "Loss: 4.011709447785428;\n",
            "Loss: 4.009721320470174;\n",
            "Loss: 4.00805363702774;\n",
            "Loss: 4.006367465577474;\n",
            "Loss: 4.005386012792587;\n",
            "Loss: 4.0040526675069055;\n",
            "Loss: 4.002225755344738;\n",
            "Loss: 4.001047143512302;\n",
            "Loss: 3.999780233839284;\n",
            "Loss: 3.9980127356914763;\n",
            "Improved from 4.011395709991455 to 3.828948956489563, saving model..\n",
            "Epoch: 3, Train loss: 3.998, Val loss: 3.829,            Epoch time=410.899s\n",
            "The original version of the “\n",
            "You ' re going to be here .\n",
            "What are we gonna do ?\n",
            "The first .\n",
            "Loss: 3.876111967563629;\n",
            "Loss: 3.8721764349937438;\n",
            "Loss: 3.877693627675374;\n",
            "Loss: 3.8769780832529066;\n",
            "Loss: 3.8754340724945067;\n",
            "Loss: 3.8728544386227926;\n",
            "Loss: 3.8698508647509984;\n",
            "Loss: 3.8688150560855865;\n",
            "Loss: 3.869650025367737;\n",
            "Loss: 3.8688181195259093;\n",
            "Loss: 3.866005831415003;\n",
            "Loss: 3.8659113387266797;\n",
            "Loss: 3.8672405417148883;\n",
            "Loss: 3.865288762535368;\n",
            "Loss: 3.8635513763427736;\n",
            "Loss: 3.862318746596575;\n",
            "Loss: 3.8605315702101763;\n",
            "Loss: 3.8598387293020884;\n",
            "Loss: 3.8596032293219316;\n",
            "Loss: 3.859006562590599;\n",
            "Loss: 3.857932733467647;\n",
            "Loss: 3.856255105408755;\n",
            "Loss: 3.855415248663529;\n",
            "Loss: 3.8552238461375237;\n",
            "Loss: 3.8535554121017457;\n",
            "Loss: 3.853892863897177;\n",
            "Loss: 3.852258219100811;\n",
            "Loss: 3.8522142877749035;\n",
            "Loss: 3.851106254561194;\n",
            "Loss: 3.8497413742542266;\n",
            "Loss: 3.8485673904418944;\n",
            "Loss: 3.8475906959176065;\n",
            "Loss: 3.8466723449302442;\n",
            "Loss: 3.8454635423071246;\n",
            "Loss: 3.8447041449546813;\n",
            "Loss: 3.8442358423603906;\n",
            "Loss: 3.8431250420776575;\n",
            "Loss: 3.8423775522332444;\n",
            "Loss: 3.8418729031391634;\n",
            "Loss: 3.8410477643013;\n",
            "Loss: 3.8402075715181305;\n",
            "Loss: 3.8392629631360373;\n",
            "Loss: 3.8384292961830315;\n",
            "Loss: 3.8379821582815863;\n",
            "Loss: 3.8376005709966026;\n",
            "Loss: 3.836426187598187;\n",
            "Loss: 3.835114283916798;\n",
            "Improved from 3.828948956489563 to 3.72340558052063, saving model..\n",
            "Epoch: 4, Train loss: 3.835, Val loss: 3.723,            Epoch time=410.691s\n",
            "Example\n",
            "Get it out .\n",
            "What are we gonna do that ?\n",
            "The whole .\n",
            "Loss: 3.7391290354728697;\n",
            "Loss: 3.7429080533981325;\n",
            "Loss: 3.748426644007365;\n",
            "Loss: 3.7460521697998046;\n",
            "Loss: 3.747323734283447;\n",
            "Loss: 3.7455691568056744;\n",
            "Loss: 3.7443319623810902;\n",
            "Loss: 3.745235569179058;\n",
            "Loss: 3.7452081547843084;\n",
            "Loss: 3.7476026935577393;\n",
            "Loss: 3.7492323784394697;\n",
            "Loss: 3.7496727307637534;\n",
            "Loss: 3.7495711675057044;\n",
            "Loss: 3.7500000498976025;\n",
            "Loss: 3.74932776037852;\n",
            "Loss: 3.7488406135141847;\n",
            "Loss: 3.7487184621306024;\n",
            "Loss: 3.746964950164159;\n",
            "Loss: 3.7459096588586505;\n",
            "Loss: 3.7449408264160158;\n",
            "Loss: 3.744640786534264;\n",
            "Loss: 3.744327812845057;\n",
            "Loss: 3.7432658833006154;\n",
            "Loss: 3.7421206786235173;\n",
            "Loss: 3.7411727277755737;\n",
            "Loss: 3.7413843231017774;\n",
            "Loss: 3.741544980384685;\n",
            "Loss: 3.741765781555857;\n",
            "Loss: 3.7415756110487313;\n",
            "Loss: 3.7410334877173104;\n",
            "Loss: 3.740730227962617;\n",
            "Loss: 3.740401953235269;\n",
            "Loss: 3.740705191077608;\n",
            "Loss: 3.7407384835271276;\n",
            "Loss: 3.740972224848611;\n",
            "Loss: 3.7413769487539925;\n",
            "Loss: 3.7414401480313892;\n",
            "Loss: 3.741128046198895;\n",
            "Loss: 3.7411610632065013;\n",
            "Loss: 3.7410436962246894;\n",
            "Loss: 3.74070620792668;\n",
            "Loss: 3.740647633189247;\n",
            "Loss: 3.740412790664407;\n",
            "Loss: 3.7407555983283305;\n",
            "Loss: 3.740538124879201;\n",
            "Loss: 3.7407922496484676;\n",
            "Loss: 3.7404716065082146;\n",
            "Improved from 3.72340558052063 to 3.6984123039245604, saving model..\n",
            "Epoch: 5, Train loss: 3.740, Val loss: 3.698,            Epoch time=410.830s\n",
            "Example\n",
            "Get it out .\n",
            "What are we gonna do that ?\n",
            "The whole .\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "\n",
        "losses = []\n",
        "\n",
        "\n",
        "print(translate(\"Пример\"))\n",
        "print(translate('Переведи вот это'))\n",
        "print(translate('Что мы с этим будем делать?'))\n",
        "print(translate('Паника'))\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train(model, training_generator, optimizer, loss_fn, scheduler, run)\n",
        "    # run.log({\"epoch_loss\": train_loss})\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(model, valid_generator, loss_fn, run)\n",
        "    # run.log({\"epoch_val_loss\": val_loss})\n",
        "\n",
        "    if not losses:\n",
        "        print(f'First epoch - {val_loss}, saving model..')\n",
        "        torch.save(model, 'model')\n",
        "\n",
        "    elif val_loss < min(losses):\n",
        "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
        "        torch.save(model, 'model')\n",
        "\n",
        "    losses.append(val_loss)\n",
        "\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
        "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))\n",
        "\n",
        "    print(translate(\"Пример\"))\n",
        "    print(translate('Переведи вот это'))\n",
        "    print(translate('Что мы с этим будем делать?'))\n",
        "    print(translate('Паника'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# пример для души\n",
        "translate('Я люблю крыс')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4w96ZkKzEQZm",
        "outputId": "b37ed9d4-c78b-4090-c1e9-fdd8392b0fd3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love with a rat .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU"
      ],
      "metadata": {
        "id": "3QcSuFcYG-SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('opus.en-ru-test.ru').read().replace('\\xa0', ' ')\n",
        "f = open('opus.en-ru-test.ru', 'w')\n",
        "f.write(text)\n",
        "f.close()\n",
        "ru_sents = open('opus.en-ru-test.ru').read().splitlines()"
      ],
      "metadata": {
        "id": "hiBdRunjHhsA"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "ru_sents = [sent for sent in ru_sents if bool(re.search(r'[A-z]', sent)) == False]\n",
        "\n",
        "ru_sample = random.sample(ru_sents, 100)\n",
        "en_sample = list()"
      ],
      "metadata": {
        "id": "FB5H5F22GiSu"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "JrqQAplCxnGJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "bleu_scores = list()\n",
        "\n",
        "for sent in ru_sample:\n",
        "    sent_to_trans = nltk.word_tokenize(sent.lower())\n",
        "    translation = nltk.word_tokenize(translate(sent).lower())\n",
        "    bleu_score = nltk.translate.bleu_score.sentence_bleu([sent_to_trans], translation, auto_reweigh=True)\n",
        "    bleu_scores.append(bleu_score)\n",
        "    en_sample.append(translation)\n",
        "\n",
        "best_trans_indices = sorted(range(len(bleu_scores)), key=lambda i: bleu_scores[i], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trans_indices = sorted(range(len(bleu_scores)), key=lambda i: bleu_scores[i], reverse=True)\n",
        "for i in range(5):\n",
        "    idx = best_trans_indices[i]\n",
        "    print('BLEU-score is ', bleu_scores[idx])\n",
        "    print(ru_sample[idx])\n",
        "    print(' '.join(en_sample[idx]))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvqDTvrxK-zH",
        "outputId": "f06f00ec-fee5-4eb1-b21f-af0d89b16659"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-score is  0.722160038719837\n",
            "Лотерея номера: 2, 11, 12, 19, 26, 41\n",
            "lottery numbers : 2 , 11 , 12 , 12 , 19 , 26 , 41\n",
            "\n",
            "\n",
            "BLEU-score is  0.2907153684841096\n",
            "Виктория (Вирджиния) 434696 **** Телефон\n",
            "victoria ( virginia ) 84796 * * * * phone\n",
            "\n",
            "\n",
            "BLEU-score is  0.2596535889340338\n",
            "Батлер (Джорджия) 478862 **** Телефон\n",
            "the beller ( georgia ) 857462 * * * * phone\n",
            "\n",
            "\n",
            "BLEU-score is  0.05209718298539206\n",
            "Письмо Председателя Комитета Совета Безопасности, учрежденного резолюцией 1373 (2001) о борьбе с терроризмом, от 19 декабря 2003 года на имя Председателя Совета Безопасности\n",
            "letter dated 2001 from the security council of the security council of the security council resolution 1373 ( 2001 ) of the security council of the security council of the security council of the security council of the security council of the security council\n",
            "\n",
            "\n",
            "BLEU-score is  6.7393716283177006e-155\n",
            "30 Ноябрь 2017, 18:30:21\n",
            "30 декабрь 2017 , 18 : 30 : 30\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_N0V8JW4lNo"
      },
      "source": [
        "# **Задание 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHe5aJ05HzEI"
      },
      "source": [
        "- В чем заключается техника back translation?\n",
        "- Для чего она применяется и что позволяет получить?\n",
        "- Опишите по шагам, как ее применить к паре en->ru на данных из семинара.\n",
        "- Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1EGkSUk2Ti5g"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}