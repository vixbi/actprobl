{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS73Yzrdvpj2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pymorphy3 pymystem3 razdel spacy\n",
        "!python -m spacy download ru_core_news_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy3 import MorphAnalyzer\n",
        "from razdel import sentenize\n",
        "from pymystem3 import Mystem\n",
        "import spacy\n",
        "import json"
      ],
      "metadata": {
        "id": "gi99oovkv27p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 1**"
      ],
      "metadata": {
        "id": "v10tx4KwTxzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import sentenize\n",
        "\n",
        "# sentenize не умеет в отсутствие пробелов для токенизации\n",
        "text = 'I love my shoes...My shoes are beautiful.'\n",
        "error_example = list(sentenize(text))\n",
        "error_example\n"
      ],
      "metadata": {
        "id": "838UYb8BwFPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb4894b-1178-4fc1-8d49-7efecd2c84ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 41, 'I love my shoes...My shoes are beautiful.')]"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задание 2**"
      ],
      "metadata": {
        "id": "D3vrmA2iT3Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# задание 2\n",
        "\n",
        "text = \"\"\"\n",
        "Вторым и третьим открытыми белыми карликами стали Сириус B и Процион B. В 1844 году директор Кёнигсбергской обсерватории Фридрих Бессель, анализируя данные наблюдений, которые велись с 1755 года, обнаружил, что Сириус, ярчайшая звезда земного неба, и Процион периодически, хотя и весьма слабо, отклоняются от прямолинейной траектории движения по небесной сфере[5]. Бессель пришёл к выводу, что у каждой из них должен быть близкий спутник. Сообщение было встречено скептически, поскольку слабый спутник оставался ненаблюдаемым, а его масса должна была быть достаточно велика — сравнимой с массой Сириуса и Проциона, соответственно.\n",
        "\n",
        "В январе 1862 года Элвин Грэхэм Кларк, юстируя 18-дюймовый рефрактор, самый большой на то время телескоп в мире (Dearborn Telescope), впоследствии поставленный семейной фирмой Кларков в обсерваторию Чикагского университета, обнаружил в непосредственной близости от Сириуса тусклую звёздочку. Это был спутник Сириуса, Сириус B, предсказанный Бесселем[6]. А в 1896 году американский астроном Д. М. Шеберле открыл Процион B, подтвердив тем самым и второе предсказание Бесселя.\n",
        "\n",
        "В 1915 году американский астроном Уолтер Сидней Адамс измерил спектр Сириуса B. Из измерений следовало, что его температура не ниже, чем у Сириуса A (по современным данным, температура поверхности Сириуса B составляет 25 000 K, а Сириуса A — 10 000 К), что, с учётом его в 10 000 раз меньшей, чем у Сириуса A, светимости указывает на очень малый радиус и, соответственно, высокую плотность — 106 г/см3 (плотность Сириуса ~0,25 г/см3, плотность Солнца ~1,4 г/см3).\n",
        "\"\"\"\n",
        "\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "razdel_raw = list(razdel_tokenize(text))\n",
        "razdel_results = []\n",
        "for i in razdel_raw:\n",
        "  razdel_results.append(i.text)\n",
        "\n",
        "mystem = Mystem(disambiguation=False)\n",
        "mystem_raw = mystem.analyze(text)\n",
        "mystem_results = []\n",
        "for i in mystem_raw:\n",
        "  mystem_results.append(i['text'])\n",
        "\n",
        "# как можно увидеть из работы mystem, он токенизирует в т. ч. пробелы\n",
        "# и отступы строк, что вообще-то не очень хорошо; давайте уберем и сравним\n",
        "# результат\n",
        "\n",
        "mystem_results_without_spaces = []\n",
        "for i in mystem_results:\n",
        "  if i != '\\n' and i != ' ':\n",
        "    mystem_results_without_spaces.append(i.strip())\n",
        "\n",
        "# сравниваем результат; также отметим, что длина списка\n",
        "# mystem_results_without_spaces = 293, в то время как у razdel_results = 292;\n",
        "# это значит, что mystem токенизировал как минимум на один символ больше\n",
        "for i in range(len(razdel_results)):\n",
        "  if mystem_results_without_spaces[i] != razdel_results[i] and i < 291:\n",
        "    print(i, mystem_results_without_spaces[i], razdel_results[i], sep='|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-K7t7qCDlnV",
        "outputId": "2f457120-53ab-41d6-dfdb-4b52f14b8dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116|18|18-дюймовый\n",
            "117|-|рефрактор\n",
            "118|дюймовый|,\n",
            "119|рефрактор|самый\n",
            "120|,|большой\n",
            "121|самый|на\n",
            "122|большой|то\n",
            "123|на|время\n",
            "124|то|телескоп\n",
            "125|время|в\n",
            "126|телескоп|мире\n",
            "127|в|(\n",
            "128|мире|Dearborn\n",
            "129|(|Telescope\n",
            "130|Dearborn|)\n",
            "131|Telescope|,\n",
            "132|),|впоследствии\n",
            "133|впоследствии|поставленный\n",
            "134|поставленный|семейной\n",
            "135|семейной|фирмой\n",
            "136|фирмой|Кларков\n",
            "137|Кларков|в\n",
            "138|в|обсерваторию\n",
            "139|обсерваторию|Чикагского\n",
            "140|Чикагского|университета\n",
            "141|университета|,\n",
            "142|,|обнаружил\n",
            "143|обнаружил|в\n",
            "144|в|непосредственной\n",
            "145|непосредственной|близости\n",
            "146|близости|от\n",
            "147|от|Сириуса\n",
            "148|Сириуса|тусклую\n",
            "149|тусклую|звёздочку\n",
            "150|звёздочку|.\n",
            "151|.|Это\n",
            "152|Это|был\n",
            "153|был|спутник\n",
            "154|спутник|Сириуса\n",
            "155|Сириуса|,\n",
            "156|,|Сириус\n",
            "157|Сириус|B\n",
            "158|B|,\n",
            "159|,|предсказанный\n",
            "160|предсказанный|Бесселем\n",
            "161|Бесселем|[\n",
            "162|[|6\n",
            "163|6|]\n",
            "164|]|.\n",
            "165|.|А\n",
            "166|А|в\n",
            "167|в|1896\n",
            "168|1896|году\n",
            "169|году|американский\n",
            "170|американский|астроном\n",
            "171|астроном|Д\n",
            "172|Д|.\n",
            "173|.|М\n",
            "174|М|.\n",
            "175|.|Шеберле\n",
            "176|Шеберле|открыл\n",
            "177|открыл|Процион\n",
            "178|Процион|B\n",
            "179|B|,\n",
            "180|,|подтвердив\n",
            "181|подтвердив|тем\n",
            "182|тем|самым\n",
            "183|самым|и\n",
            "184|и|второе\n",
            "185|второе|предсказание\n",
            "186|предсказание|Бесселя\n",
            "187|Бесселя|.\n",
            "188|.|В\n",
            "189|В|1915\n",
            "190|1915|году\n",
            "191|году|американский\n",
            "192|американский|астроном\n",
            "193|астроном|Уолтер\n",
            "194|Уолтер|Сидней\n",
            "195|Сидней|Адамс\n",
            "196|Адамс|измерил\n",
            "197|измерил|спектр\n",
            "198|спектр|Сириуса\n",
            "199|Сириуса|B\n",
            "200|B|.\n",
            "201|.|Из\n",
            "202|Из|измерений\n",
            "203|измерений|следовало\n",
            "204|следовало|,\n",
            "205|,|что\n",
            "206|что|его\n",
            "207|его|температура\n",
            "208|температура|не\n",
            "209|не|ниже\n",
            "210|ниже|,\n",
            "211|,|чем\n",
            "212|чем|у\n",
            "213|у|Сириуса\n",
            "214|Сириуса|A\n",
            "215|A|(\n",
            "216|(|по\n",
            "217|по|современным\n",
            "218|современным|данным\n",
            "219|данным|,\n",
            "220|,|температура\n",
            "221|температура|поверхности\n",
            "222|поверхности|Сириуса\n",
            "223|Сириуса|B\n",
            "224|B|составляет\n",
            "225|составляет|25\n",
            "226|25|000\n",
            "227|000|K\n",
            "228|K|,\n",
            "229|,|а\n",
            "230|а|Сириуса\n",
            "231|Сириуса|A\n",
            "232|A|—\n",
            "233|—|10\n",
            "234|10|000\n",
            "235|000|К\n",
            "236|К|)\n",
            "237|),|,\n",
            "270|см3|см\n",
            "271|(|3\n",
            "272|плотность|(\n",
            "273|Сириуса|плотность\n",
            "274|~|Сириуса\n",
            "275|0|~\n",
            "276|,|0,25\n",
            "277|25|г\n",
            "278|г|/\n",
            "279|/|см\n",
            "280|см3|3\n",
            "285|1|1,4\n",
            "286|,|г\n",
            "287|4|/\n",
            "288|г|см\n",
            "289|/|3\n",
            "290|см3|)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как можно увидеть, проблема возникла с токенизацией \"18-дюймовый\": MyStem посчитал это слово как три токена, в то время как Razdel интерпретировал его как один; при этом в 132 элементе MyStem ***), ***слепил в один токен, а Razdel их разделяет (извините за каламбур). Все это подводит нас к выводу, что razdel все же использовать более продуктивно, чем mystem:\n",
        "- меньше количество учитываемых факторов при извчелении токенов (что можно увидеть даже по количеству строк, которое я посвятила каждому из них)\n",
        "- более понятные \"правила игры\": не очень понятно, в каких случаях MyStem интерпретирует знаки препинания как отдельные токены, а когда не разделяет две разные сущности."
      ],
      "metadata": {
        "id": "pZHh4hoVTOwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 3**"
      ],
      "metadata": {
        "id": "bUK4k6hfTtZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mystem_lem = mystem.lemmatize(text)\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "pymorphy_lem_raw = [morph.parse(i) for i in mystem_results]\n",
        "pymorphy_lem = []\n",
        "for i in range(len(pymorphy_lem_raw)):\n",
        "  pymorphy_lem.append(pymorphy_lem_raw[i][0].normal_form)\n",
        "\n",
        "# сравниваем\n",
        "mst_pym = 0\n",
        "for i in range(len(pymorphy_lem)):\n",
        "  if mystem_lem[i] != pymorphy_lem[i]:\n",
        "    print(i, mystem_lem[i], pymorphy_lem[i], sep='|')\n",
        "  if mystem_lem[i] == pymorphy_lem[i]:\n",
        "    mst_pym += 1\n",
        "print('Общее у pymorphy и mystem: ', round(mst_pym/len(pymorphy_lem)*100, 2),\n",
        "      '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqcyb8A-NxuG",
        "outputId": "c9c8f547-cbab-4772-9446-e847a396f2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13|становиться|стать\n",
            "17|B|b\n",
            "23|B|b\n",
            "33|кенигсбергский|кёнигсбергский\n",
            "43|данные|дать\n",
            "57|обнаруживать|обнаружить\n",
            "106|приходить|прийти\n",
            "134|встречать|встретить\n",
            "190|грэхэм|грэхэма\n",
            "218|Dearborn|dearborn\n",
            "220|Telescope|telescope\n",
            "224|поставлять|поставить\n",
            "240|обнаруживать|обнаружить\n",
            "254|звездочка|звёздочка\n",
            "266|B|b\n",
            "268|предсказывать|предсказать\n",
            "287|д|далее\n",
            "291|шеберля|шеберл\n",
            "293|открывать|открыть\n",
            "297|B|b\n",
            "301|то|тем\n",
            "307|второй|второе\n",
            "331|измерять|измерить\n",
            "337|B|b\n",
            "353|низко|ниже\n",
            "361|A|a\n",
            "375|B|b\n",
            "383|K|k\n",
            "389|A|a\n",
            "401|учет|учёт\n",
            "413|меньший|малый\n",
            "421|A|a\n",
            "Общее у pymorphy и mystem:  93.26 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проблемы MyStem:**\n",
        "\n",
        "*  склонен интерпретировать глаголы совершенного вида как глаголы несовершенного вида (13: *стали* как *становиться*; 240: *обнаружил* - как *обнаруживать* и т. д.)\n",
        "*   исчезновение буквы ё (401: *учет*), что в принципе не такая уж проблема, но может ею стать, если мы будем сталкиваться с неоднозначными кейсами\n",
        "\n",
        "**Проблемы PyMorphy:**\n",
        "*   иногда мудрит и делает слишком много работы (типа приведения к нижнему регистру букв у звезд или лемматизация *меньший* как *малый*, хотя это достаточно спорный компаратив; с именами та же проблема)\n",
        "*   иногда, наоборот, не доделывает необходимый минимум: явный компаратив *ниже* у него остался без изменений\n",
        "\n",
        "Оба товарища не справились с фамилиями Грэхема и Шеребле. Возможно, есть еще формы, которые они интерпретировали неверно, но одинаково.\n"
      ],
      "metadata": {
        "id": "JRDfIkSrUPH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Задание 4**"
      ],
      "metadata": {
        "id": "XQM0_J5hXPOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mystem_tokenizer(text):\n",
        "    tokens = []\n",
        "    for token in mystem.analyze(text):\n",
        "      tokens.append(token[\"text\"])\n",
        "    return spacy.tokens.Doc(nlp.vocab, tokens)\n",
        "\n",
        "nlp.tokenizer = mystem_tokenizer\n",
        "spacy_res = nlp(text)\n",
        "spacy_lem = []\n",
        "for sent in spacy_res.sents:\n",
        "    for token in sent:\n",
        "        spacy_lem.append(token.lemma_.lower())\n",
        "\n",
        "# сравнение\n",
        "sp_pym = 0\n",
        "sp_mst = 0\n",
        "for i in range(len(spacy_lem)):\n",
        "  if mystem_lem[i] != spacy_lem[i] or spacy_lem[i]!=pymorphy_lem[i]:\n",
        "    print(i, mystem_lem[i], pymorphy_lem[i], spacy_lem[i], sep='|')\n",
        "  if mystem_lem[i] == spacy_lem[i]:\n",
        "    sp_mst += 1\n",
        "  if pymorphy_lem[i] == spacy_lem[i]:\n",
        "    sp_pym += 1\n",
        "\n",
        "print('Общее у SpaCy и MyStem: ', round(sp_mst/len(spacy_lem)*100, 2), '%',\n",
        "      '\\n',\n",
        "      'Общее у SpaCy и PyMorphy: ', round(sp_pym/len(spacy_lem)*100, 2), '%',\n",
        "      '\\n',\n",
        "      'Общее у PyMorphy и MyStem: ', round(mst_pym/len(pymorphy_lem)*100, 2),\n",
        "      '%',\n",
        "      sep='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqmugAJaSikP",
        "outputId": "65ce6118-43a5-458b-aa5a-e1756a3ead92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13|становиться|стать|стать\n",
            "17|B|b|b\n",
            "23|B|b|b\n",
            "33|кенигсбергский|кёнигсбергский|кёнигсбергский\n",
            "43|данные|дать|данные\n",
            "47|который|который|которые\n",
            "57|обнаруживать|обнаружить|обнаружить\n",
            "63|яркий|яркий|ярчайшая\n",
            "106|приходить|прийти|прийти\n",
            "120|они|они|них\n",
            "132|быть|быть|было\n",
            "134|встречать|встретить|встретить\n",
            "174|процион|процион|проциона\n",
            "190|грэхэм|грэхэма|грэхэм\n",
            "208|то|то|тот\n",
            "218|Dearborn|dearborn|dearborn\n",
            "220|Telescope|telescope|telescope\n",
            "224|поставлять|поставить|поставить\n",
            "230|кларк|кларк|кларков\n",
            "236|чикагский|чикагский|чикагского\n",
            "240|обнаруживать|обнаружить|обнаружить\n",
            "254|звездочка|звёздочка|звёздочка\n",
            "266|B|b|b\n",
            "268|предсказывать|предсказать|предсказанный\n",
            "270|бессель|бессель|бесселем\n",
            "287|д|далее|д\n",
            "291|шеберля|шеберл|шеберле\n",
            "293|открывать|открыть|открыть\n",
            "297|B|b|b\n",
            "301|то|тем|тем\n",
            "303|самый|самый|самым\n",
            "307|второй|второе|второй\n",
            "311|бессель|бессель|бесселя\n",
            "331|измерять|измерить|измерить\n",
            "337|B|b|b\n",
            "353|низко|ниже|низкий\n",
            "361|A|a|a\n",
            "367|данные|данные|данным\n",
            "375|B|b|b\n",
            "383|K|k|k\n",
            "389|A|a|a\n",
            "401|учет|учёт|учёт\n",
            "403|он|он|его\n",
            "413|меньший|малый|малый\n",
            "421|A|a|a\n",
            "Общее у SpaCy и MyStem: 91.37%\n",
            "Общее у SpaCy и PyMorphy: 95.79%\n",
            "Общее у PyMorphy и MyStem: 93.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы по сравнению:\n",
        "\n",
        "\n",
        "*   SpaCy больше похож на PyMorphy: в плюсах та же буква ё и умение в вид глагола\n",
        "* При этом SpaCy поправил косяк с *низким-ниже*\n",
        "*   SpaCy, судя по всему, не очень могет в падежные окончания, потому что некоторые штуки он вообще оставил без лемматизации (типа *чикагского*)\n",
        "*  SpaCy справился с Шеребле!"
      ],
      "metadata": {
        "id": "1b8zsoXKp_25"
      }
    }
  ]
}