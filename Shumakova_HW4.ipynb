{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vixbi/actprobl/blob/main/Shumakova_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545a3072-0839-44e4-8f48-0206b15316b3",
      "metadata": {
        "id": "545a3072-0839-44e4-8f48-0206b15316b3"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "import numpy as np\n",
        "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix\n",
        "from collections import Counter\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea0b8114-f1e1-42c8-8613-4e8d926abc2a",
      "metadata": {
        "id": "ea0b8114-f1e1-42c8-8613-4e8d926abc2a"
      },
      "source": [
        "## Задание 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95f0c20-f849-4994-a888-c737f4aaeba6",
      "metadata": {
        "id": "d95f0c20-f849-4994-a888-c737f4aaeba6"
      },
      "outputs": [],
      "source": [
        "dvach = open('2ch_corpus.txt').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b623437-d1f6-4730-9a14-5231b4b37c29",
      "metadata": {
        "id": "6b623437-d1f6-4730-9a14-5231b4b37c29"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word \\\n",
        "                                                            in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n",
        "\n",
        "# в конце отложила первые 100 предложений\n",
        "sentences_dvach =  [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach[:5000000])][100:]\n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "unigrams_dvach = Counter()\n",
        "bigram_dvach = Counter()\n",
        "trigram_dvach = Counter()\n",
        "\n",
        "for sentence in sentences_dvach:\n",
        "    unigrams_dvach.update(sentence)\n",
        "    bigram_dvach.update(ngrammer(sentence, n=2))\n",
        "    trigram_dvach.update(ngrammer(sentence, n=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee85544-01bf-4501-90bf-74ddb34a8979",
      "metadata": {
        "id": "6ee85544-01bf-4501-90bf-74ddb34a8979"
      },
      "outputs": [],
      "source": [
        "matrix_dvach = lil_matrix((len(bigram_dvach), len(unigrams_dvach)))\n",
        "\n",
        "id2word_dvach = list(unigrams_dvach)\n",
        "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
        "id2bigrams_dvach = list(bigram_dvach)\n",
        "word2idbigrams_dvach = {word:i for i, word in enumerate(id2bigrams_dvach)}\n",
        "\n",
        "for ngram in trigram_dvach:\n",
        "    word_bigram, word_unigram = ngram.rsplit(\" \", 1)\n",
        "    matrix_dvach[word2idbigrams_dvach[word_bigram], word2id_dvach[word_unigram]] =  (trigram_dvach[ngram]/\n",
        "                                                                     bigram_dvach[word_bigram])\n",
        "matrix_dvach = csc_matrix(matrix_dvach)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72b39ce-c869-47b5-976a-bf06069ba5ae",
      "metadata": {
        "id": "e72b39ce-c869-47b5-976a-bf06069ba5ae"
      },
      "outputs": [],
      "source": [
        "def generate(matrix, id2word, word2id, n=100, start='<start> <start>'):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "    previous = [\"<start>\"]\n",
        "\n",
        "    for i in range(n):\n",
        "        chosen_index = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
        "        text.append(id2word[chosen_index])\n",
        "\n",
        "        chosen = id2word[chosen_index]\n",
        "        text.append(chosen)\n",
        "        if chosen == \"<end>\":\n",
        "            previous = [\"<start>\"]\n",
        "            chosen = \"<start>\"\n",
        "\n",
        "        previous.append(chosen)\n",
        "        current_idx = word2id[\" \".join(previous)]\n",
        "        previous = previous[1:]\n",
        "\n",
        "    res_text = []\n",
        "    prev = ''\n",
        "    for i in text:\n",
        "        if prev != i:\n",
        "            res_text.append(i)\n",
        "        prev = i\n",
        "\n",
        "    return ' '.join(res_text).replace('<end>', '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38d92e2c-72eb-4c1f-9966-d043f36434b2",
      "metadata": {
        "id": "38d92e2c-72eb-4c1f-9966-d043f36434b2",
        "outputId": "66021ecb-e053-4c2a-d9c0-88c4ee3efdbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 \n",
            " два чая иншаллах \n",
            " все в хламину отсутствие безумных проков которые были после марки передаёте этот пиздёж про нирвану и возвышенное существование остаётся пиздежом поскольку во-первых его никто не верит никто и не млекопитающее \n",
            " вкратце пётр дегтярев \n",
            " в шапке треда \n",
            " я чего-то не вижу мусора трупов алкашей и вот совсем адская мухосрань \n",
            " и тут не текстовые рпг наоборот ж я пытаюсь вам открыть глаза \n",
            " а можно как-то найти что-то общее ничего усачев не знает кто сбил боинг и кто ее трахал \n",
            " я всегда охуеваю вот с замедлением вдруг стало лучше но никто\n"
          ]
        }
      ],
      "source": [
        "#генерация 1\n",
        "print(generate(matrix_dvach, id2word_dvach, word2idbigrams_dvach))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0097bfd7-66fa-4fd6-9b76-2738a69cf12c",
      "metadata": {
        "id": "0097bfd7-66fa-4fd6-9b76-2738a69cf12c",
        "outputId": "33a9104b-9a62-4ac9-bd43-bb977286f634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ты еще и зарабатывает на долге \n",
            " боко харам в афганистан где как раз пройдет \n",
            " быстренько да для ачивки \n",
            " ёбаный сиетл заходишь на видеохостинг тытруба в топе стима тоже не хотел их делать \n",
            " что за хуйню ты слушаешь пудель зачем ты сидишь тут праведный такой \n",
            " скорее всего еще меньше \n",
            " каких там солей говоришь надо \n",
            " а дробить на 10 метрах \n",
            " походу ей пизда пришла схуяли она промахивается на 10 морская свинка \n",
            " ну и фантазии про по морде мы уже придали тебя забвению \n",
            " не бомби ты так делай \n",
            " игишня сама говорила что\n"
          ]
        }
      ],
      "source": [
        "#генерация 2\n",
        "print(generate(matrix_dvach, id2word_dvach, word2idbigrams_dvach))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f319e0-9f35-4687-a30e-4b927e9a5441",
      "metadata": {
        "id": "93f319e0-9f35-4687-a30e-4b927e9a5441",
        "outputId": "60aa350b-af72-4478-ac63-a25d5cc5d754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "одно дело где я теперь вне закона \n",
            " может кто решил проблему \n",
            " чтоб не обосраться \n",
            " только в библиотеках ультрахардкор молодость мытищи 359 \n",
            " но четкий числовой ответ тут дать невозможно \n",
            " мань перед тем как найти хоть шмотки какие нибудь судебные процессы и прочая хуйня не слушай его больше не согласится на использование тех данных которые уже купили их у меня где-то так лоал \n",
            " нераскрытый потенциал спроси хотела бы я без нее кун \n",
            " вы соринки в наших пердях годные терапевты водятся \n",
            " ты же должен работать обман с оформлением по разным причинам даже если нет количество\n"
          ]
        }
      ],
      "source": [
        "#генерация 3\n",
        "print(generate(matrix_dvach, id2word_dvach, word2idbigrams_dvach))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2b22a39-b3fe-49bf-8b30-9ae9bb429b10",
      "metadata": {
        "id": "d2b22a39-b3fe-49bf-8b30-9ae9bb429b10"
      },
      "source": [
        "Рассчет перплексии:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb8e9c1a-2ae3-48e7-b12b-eefc30c36a33",
      "metadata": {
        "id": "eb8e9c1a-2ae3-48e7-b12b-eefc30c36a33"
      },
      "outputs": [],
      "source": [
        "def perplexity(logp, N):\n",
        "    return np.exp((-1/N) * logp)\n",
        "\n",
        "def compute_joint_proba(text, word_probas):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for word in tokens:\n",
        "        if word in word_probas:\n",
        "            prob += (np.log(word_probas[word]))\n",
        "        else:\n",
        "            prob += np.log(2e-4)\n",
        "\n",
        "    return prob, len(tokens)\n",
        "\n",
        "\n",
        "def compute_join_proba_markov_assumption(text, word_counts, bigram_counts):\n",
        "    prob = 0\n",
        "    tokens = normalize(phrase)\n",
        "    for ngram in ngrammer(['<start>'] + tokens + ['<end>']):\n",
        "        word1, word2 = ngram.split()\n",
        "        if word1 in word_counts and ngram in bigram_counts:\n",
        "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
        "        else:\n",
        "            prob += np.log(2e-5)\n",
        "\n",
        "    return prob, len(tokens)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}