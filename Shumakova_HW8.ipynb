{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjj6QQRyHlz9+VkEYJ0BN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vixbi/actprobl/blob/main/Shumakova_HW8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT8Cg0IKXxPH"
      },
      "outputs": [],
      "source": [
        "# импорт библиотек\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "import keras\n",
        "import os, re\n",
        "import numpy as np\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import keras, torch\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка датасета"
      ],
      "metadata": {
        "id": "Ex8grof6YVU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"lenta_sample.csv\")\n",
        "\n",
        "texts = data.text.values\n",
        "id2label = {i:l for i,l in enumerate(set(data.topic))}\n",
        "label2id = {l:i for i,l in id2label.items()}\n",
        "targets = [label2id[l] for l in data.topic]\n",
        "\n",
        "train_texts, valid_texts, train_targets, valid_targets = train_test_split(texts, targets, test_size=0.05)"
      ],
      "metadata": {
        "id": "0oo11OfPZf1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Общие классы и функции для моделей"
      ],
      "metadata": {
        "id": "NmVHmSXlva2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, MAX_LEN, texts, targets):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = [torch.LongTensor(tokenizer.encode(t)[:MAX_LEN]) for t in texts]\n",
        "        self.texts = torch.nn.utils.rnn.pad_sequence(self.texts, batch_first=True,\n",
        "                                                     padding_value=self.tokenizer.pad_token_id)\n",
        "\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "        self.length = len(texts)\n",
        "\n",
        "        self.target = torch.LongTensor(targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ids = self.texts[index]\n",
        "        y = self.target[index]\n",
        "\n",
        "        return ids, y\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        tokens = text.lower().split()\n",
        "        tokens = [token.strip(punctuation) for token in tokens]\n",
        "        tokens = [token for token in tokens if token]\n",
        "        return tokens"
      ],
      "metadata": {
        "id": "GqwNF2rNYGXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функции для обучения\n",
        "def train(model, iterator, optimizer, criterion, print_every=1000):\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_f1 = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, (texts, ys) in enumerate(iterator):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(texts.to(device)).squeeze()\n",
        "        loss = criterion(predictions, ys.to(device))\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = predictions.detach().to('cpu').numpy().argmax(1).tolist()\n",
        "        y_true = ys.tolist()\n",
        "\n",
        "        epoch_loss.append(loss.item())\n",
        "        epoch_f1.append(f1_score(y_true, preds, average=\"micro\"))\n",
        "\n",
        "        if not (i+1) % print_every:\n",
        "            print(f'Loss: {np.mean(epoch_loss)}; F1 measure: {np.mean(epoch_f1)}')\n",
        "\n",
        "    return np.mean(epoch_f1)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_f1 = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, ys in iterator:\n",
        "\n",
        "            predictions = model(texts.to(device)).squeeze()\n",
        "            loss = criterion(predictions, ys.to(device))\n",
        "            preds = predictions.detach().to('cpu').numpy().argmax(1).tolist()\n",
        "            y_true = ys.tolist()\n",
        "\n",
        "\n",
        "            epoch_loss.append(loss.item())\n",
        "            epoch_f1.append(f1_score(y_true, preds, average=\"micro\"))\n",
        "\n",
        "    return np.mean(epoch_f1)# / len(iterator)\n",
        "\n",
        "def predict(model, iterator):\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, ys in iterator:\n",
        "            predictions = model(texts.to(device)).squeeze()\n",
        "            ys = predictions.detach().to('cpu').numpy().argmax(1).tolist()\n",
        "            preds.extend(ys)\n",
        "\n",
        "    return preds"
      ],
      "metadata": {
        "id": "rqpKD6ODaZJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CLF(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_model, num_classes, avg_pool=False):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer # токенизатор\n",
        "        self.pretrained_model = pretrained_model # предобученная модель\n",
        "        self.drop = nn.Dropout(0.3) # добавим дропаут чтобы не переобучалось\n",
        "        self.fc = nn.Linear(768, num_classes)\n",
        "        self.act = nn.LogSoftmax(1)\n",
        "\n",
        "    def forward(self, texts):\n",
        "\n",
        "        mask = (texts != tokenizer.pad_token_id).long()\n",
        "\n",
        "        # прогоняем через BERT\n",
        "        hidden = self.pretrained_model(texts, attention_mask=mask)[0]\n",
        "\n",
        "        if self.avg_pool == False:\n",
        "            # берем самое первое состояние и применяем к нему линейный слой и активацию\n",
        "            to_drop = hidden[:,0]\n",
        "        elif self.avg_pool == True:\n",
        "            to_drop = hidden.mean(1)\n",
        "\n",
        "        outputs=self.act(self.fc(self.drop(to_drop)))\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "yzlb-uUEalzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение modernbert-base целиком"
      ],
      "metadata": {
        "id": "L7eWKI5nYAPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ],
      "metadata": {
        "id": "nx6jSgrAu4n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"answerdotai/ModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model_modernbert = AutoModel.from_pretrained(model_id)\n",
        "MAX_LEN = 512\n",
        "training_set = Dataset(tokenizer, MAX_LEN, train_texts, train_targets)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True, )\n",
        "valid_set = Dataset(tokenizer, MAX_LEN, valid_texts, valid_targets)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CLF(model_modernbert, len(label2id))\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.NLLLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(\"Percentage of trainable params:\")\n",
        "print('{0:.10f}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)/sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "id": "vZySRmORa0Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "E-61Dsbuu9dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "f1s_eval = []\n",
        "\n",
        "for i in range(30):\n",
        "    print(i)\n",
        "    f1s.append(train(model, training_generator, optimizer, criterion, 2000))\n",
        "    evl = evaluate(model, valid_generator, criterion)\n",
        "    print('Eval - ', evl)\n",
        "    f1s_eval.append(evl)"
      ],
      "metadata": {
        "id": "nnKdy7GEcZ31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# визуализация\n",
        "plt.plot(f1s)\n",
        "plt.plot(f1s_eval)\n",
        "plt.title(\"model f1 micro\")\n",
        "plt.ylabel(\"f1\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sJQ3tINktgS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "preds = predict(model, valid_generator)\n",
        "print(classification_report(valid_targets, preds))"
      ],
      "metadata": {
        "id": "bZoG7evdto67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение rumodernbert-base"
      ],
      "metadata": {
        "id": "xGKxRTeAYIWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ],
      "metadata": {
        "id": "RNuMPUYsvEDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"deepvk/RuModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model_modernbert = AutoModel.from_pretrained(model_id)\n",
        "MAX_LEN = 512\n",
        "training_set = Dataset(tokenizer, MAX_LEN, train_texts, train_targets)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True, )\n",
        "valid_set = Dataset(tokenizer, MAX_LEN, valid_texts, valid_targets)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CLF(model_modernbert, len(label2id))\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.NLLLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(\"Percentage of trainable params:\")\n",
        "print('{0:.10f}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)/sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "id": "MY47JoWMv1rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "3HUQaHQvvGPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "f1s_eval = []\n",
        "\n",
        "for i in range(30):\n",
        "    print(i)\n",
        "    f1s.append(train(model, training_generator, optimizer, criterion, 2000))\n",
        "    evl = evaluate(model, valid_generator, criterion)\n",
        "    print('Eval - ', evl)\n",
        "    f1s_eval.append(evl)"
      ],
      "metadata": {
        "id": "6SdOeEXixIb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# визуализация\n",
        "plt.plot(f1s)\n",
        "plt.plot(f1s_eval)\n",
        "plt.title(\"model f1 micro\")\n",
        "plt.ylabel(\"f1\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C_53tOeR5ttX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "preds = predict(model, valid_generator)\n",
        "print(classification_report(valid_targets, preds))"
      ],
      "metadata": {
        "id": "sKUpXenF50pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение modernbert-base с заморозкой"
      ],
      "metadata": {
        "id": "LYGN6Vgv3cVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ],
      "metadata": {
        "id": "X9ebWNbg4Mac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"answerdotai/ModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "for param in model_modernbert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model_modernbert = AutoModel.from_pretrained(model_id)\n",
        "MAX_LEN = 512\n",
        "training_set = Dataset(tokenizer, MAX_LEN, train_texts, train_targets)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True, )\n",
        "valid_set = Dataset(tokenizer, MAX_LEN, valid_texts, valid_targets)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CLF(model_modernbert, len(label2id))\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.NLLLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(\"Percentage of trainable params:\")\n",
        "print('{0:.10f}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)/sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "id": "inOwiofY4IMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "vmdVn2ju5OYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "f1s_eval = []\n",
        "\n",
        "for i in range(40):\n",
        "    print(i)\n",
        "    f1s.append(train(model, training_generator, optimizer, criterion, 2000))\n",
        "    evl = evaluate(model, valid_generator, criterion)\n",
        "    print('Eval - ', evl)\n",
        "    f1s_eval.append(evl)"
      ],
      "metadata": {
        "id": "QGrTJ9Hb5RNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# визуализация\n",
        "plt.plot(f1s)\n",
        "plt.plot(f1s_eval)\n",
        "plt.title(\"model f1 micro\")\n",
        "plt.ylabel(\"f1\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iZNaqpBR5-Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "preds = predict(model, valid_generator)\n",
        "print(classification_report(valid_targets, preds))"
      ],
      "metadata": {
        "id": "i3xmYlvA5-re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение rumodernbert-base с заморозкой (cls)"
      ],
      "metadata": {
        "id": "e4tylzJ13k8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ],
      "metadata": {
        "id": "KBdxlZNr6Ssh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"deepvk/RuModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "for param in model_modernbert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model_modernbert = AutoModel.from_pretrained(model_id)\n",
        "MAX_LEN = 512\n",
        "training_set = Dataset(tokenizer, MAX_LEN, train_texts, train_targets)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True, )\n",
        "valid_set = Dataset(tokenizer, MAX_LEN, valid_texts, valid_targets)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CLF(model_modernbert, len(label2id))\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.NLLLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(\"Percentage of trainable params:\")\n",
        "print('{0:.10f}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)/sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "id": "70cDf_OP3wmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "4LbciCOz6Uh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "f1s_eval = []\n",
        "\n",
        "for i in range(40):\n",
        "    print(i)\n",
        "    f1s.append(train(model, training_generator, optimizer, criterion, 2000))\n",
        "    evl = evaluate(model, valid_generator, criterion)\n",
        "    print('Eval - ', evl)\n",
        "    f1s_eval.append(evl)"
      ],
      "metadata": {
        "id": "NLm95UzTBSqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(f1s)\n",
        "plt.plot(f1s_eval)\n",
        "plt.title('model f1 micro')\n",
        "plt.ylabel('f1')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9-QVEHQxBVkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "preds = predict(model, valid_generator)\n",
        "print(classification_report(valid_targets, preds))"
      ],
      "metadata": {
        "id": "TGqB2MoyBZ7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дообучение rumodernbert-base с заморозкой (усредненный hidden_state)"
      ],
      "metadata": {
        "id": "M1w1UmL23xkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка"
      ],
      "metadata": {
        "id": "evbTMDDADbBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"deepvk/RuModernBERT-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model_modernbert = AutoModel.from_pretrained(model_id)\n",
        "MAX_LEN = 512\n",
        "training_set = Dataset(tokenizer, MAX_LEN, train_texts, train_targets)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=16, shuffle=True, )\n",
        "valid_set = Dataset(tokenizer, MAX_LEN, valid_texts, valid_targets)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CLF(model_modernbert, len(label2id), avg_pool=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.NLLLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(\"Percentage of trainable params:\")\n",
        "print('{0:.10f}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)/sum(p.numel() for p in model.parameters())))"
      ],
      "metadata": {
        "id": "iAVdCFlgDdM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "rqbZNpMEDn-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "f1s_eval = []\n",
        "\n",
        "for i in range(40):\n",
        "    print(i)\n",
        "    f1s.append(train(model, training_generator, optimizer, criterion, 2000))\n",
        "    evl = evaluate(model, valid_generator, criterion)\n",
        "    print('Eval - ', evl)\n",
        "    f1s_eval.append(evl)"
      ],
      "metadata": {
        "id": "XcpcTaNODnc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# визуализация\n",
        "plt.plot(f1s)\n",
        "plt.plot(f1s_eval)\n",
        "plt.title(\"model f1 micro\")\n",
        "plt.ylabel(\"f1\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EM4NXbUIDt_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)\n",
        "preds = predict(model, valid_generator)\n",
        "print(classification_report(valid_targets, preds))"
      ],
      "metadata": {
        "id": "inGwcA_8DwaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}